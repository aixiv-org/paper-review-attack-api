#!/usr/bin/env python3
"""
å®Œæ•´å®éªŒè¿è¡Œè„šæœ¬
æ‰§è¡Œå®Œæ•´çš„æ•°æ®æ”¶é›†ã€æ”»å‡»ç”Ÿæˆã€æ£€æµ‹å’Œè¯„ä¼°æµç¨‹
"""

import sys
import os
import argparse
from pathlib import Path
import json
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.data_collector import ArxivDatasetCollector
from src.attack_generator import AttackSampleGenerator, AdvancedAttackGenerator
from src.detector import PromptInjectionDetector, EnsembleDetector
from src.evaluator import ExperimentEvaluator
from src.utils import setup_logging, load_config, save_results

def run_data_collection(config, args, logger):
    """è¿è¡Œæ•°æ®æ”¶é›†é˜¶æ®µ"""
    logger.info("ğŸ”„ é˜¶æ®µ 1: æ•°æ®æ”¶é›†")
    logger.info("-" * 40)
    
    if args.skip_download:
        # å°è¯•åŠ è½½ç°æœ‰æ–‡ä»¶
        download_dir = Path(config['data_collection']['download_dir'])
        file_list_path = download_dir / "downloaded_files.txt"
        
        if file_list_path.exists():
            with open(file_list_path, 'r', encoding='utf-8') as f:
                clean_files = [line.strip() for line in f if line.strip()]
            logger.info(f"è·³è¿‡ä¸‹è½½ï¼ŒåŠ è½½ç°æœ‰æ–‡ä»¶: {len(clean_files)} ä¸ª")
        else:
            logger.warning("è·³è¿‡ä¸‹è½½ä½†æœªæ‰¾åˆ°ç°æœ‰æ–‡ä»¶åˆ—è¡¨ï¼Œå°†è¿›è¡Œä¸‹è½½")
            args.skip_download = False
    
    if not args.skip_download:
        collector = ArxivDatasetCollector(config)
        clean_files = collector.collect_multi_category_papers()
        
        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        stats = collector.get_paper_statistics()
        logger.info(f"æ•°æ®æ”¶é›†å®Œæˆ: {json.dumps(stats, indent=2, ensure_ascii=False)}")
    
    return clean_files

def run_attack_generation(config, clean_files, args, logger):
    """è¿è¡Œæ”»å‡»ç”Ÿæˆé˜¶æ®µ"""
    logger.info("\nğŸ”„ é˜¶æ®µ 2: æ”»å‡»æ ·æœ¬ç”Ÿæˆ")
    logger.info("-" * 40)
    
    if args.skip_attack_gen:
        # å°è¯•åŠ è½½ç°æœ‰æ”»å‡»æ ·æœ¬
        output_dir = Path(config['attack_generation']['output_dir'])
        attack_list_path = output_dir / "generated_attacks.json"
        
        if attack_list_path.exists():
            with open(attack_list_path, 'r', encoding='utf-8') as f:
                attack_data = json.load(f)
            attack_files = attack_data.get('generated_files', [])
            attack_info = attack_data.get('attack_info', [])
            logger.info(f"è·³è¿‡æ”»å‡»ç”Ÿæˆï¼ŒåŠ è½½ç°æœ‰æ ·æœ¬: {len(attack_files)} ä¸ª")
            return attack_files, attack_info
        else:
            logger.warning("è·³è¿‡æ”»å‡»ç”Ÿæˆä½†æœªæ‰¾åˆ°ç°æœ‰æ”»å‡»æ ·æœ¬ï¼Œå°†è¿›è¡Œç”Ÿæˆ")
            args.skip_attack_gen = False
    
    if not args.skip_attack_gen:
        if args.advanced_attacks:
            generator = AdvancedAttackGenerator(config)
            logger.info("ä½¿ç”¨é«˜çº§æ”»å‡»ç”Ÿæˆå™¨")
        else:
            generator = AttackSampleGenerator(config)
            logger.info("ä½¿ç”¨æ ‡å‡†æ”»å‡»ç”Ÿæˆå™¨")
        
        attack_files = generator.generate_attack_samples(clean_files)
        attack_info = generator.attack_samples
        
        # ä¿å­˜æ”»å‡»ä¿¡æ¯
        stats = generator.get_attack_statistics()
        logger.info(f"æ”»å‡»ç”Ÿæˆå®Œæˆ: {json.dumps(stats, indent=2, ensure_ascii=False)}")
    
    return attack_files, attack_info

def run_detection_evaluation(config, clean_files, attack_files, attack_info, args, logger):
    """è¿è¡Œæ£€æµ‹å’Œè¯„ä¼°é˜¶æ®µ"""
    logger.info("\nğŸ”„ é˜¶æ®µ 3: æ£€æµ‹å’Œè¯„ä¼°")
    logger.info("-" * 40)
    
    # åˆ›å»ºæ£€æµ‹å™¨
    if args.ensemble_detector:
        detector = EnsembleDetector(config)
        logger.info("ä½¿ç”¨é›†æˆæ£€æµ‹å™¨")
    else:
        detector = PromptInjectionDetector(config)
        logger.info("ä½¿ç”¨æ ‡å‡†æ£€æµ‹å™¨")
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = ExperimentEvaluator(config)
    
    # é™åˆ¶æ ·æœ¬æ•°é‡ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if args.max_samples:
        clean_files = clean_files[:args.max_samples]
        attack_files = attack_files[:args.max_samples]
        logger.info(f"é™åˆ¶æ ·æœ¬æ•°é‡ä¸º: {args.max_samples}")
    
    # è¿è¡Œè¯„ä¼°
    df_results, metrics = evaluator.evaluate_detection_performance(
        clean_files, attack_files, detector, attack_info
    )
    
    return evaluator, df_results, metrics

def main():
    parser = argparse.ArgumentParser(description='è¿è¡Œå®Œæ•´å®éªŒæµç¨‹')
    parser.add_argument('--config', type=str, default='config/config.yaml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    
    # æµç¨‹æ§åˆ¶å‚æ•°
    parser.add_argument('--skip-download', action='store_true',
                       help='è·³è¿‡æ•°æ®ä¸‹è½½é˜¶æ®µ')
    parser.add_argument('--skip-attack-gen', action='store_true',
                       help='è·³è¿‡æ”»å‡»ç”Ÿæˆé˜¶æ®µ')
    parser.add_argument('--skip-evaluation', action='store_true',
                       help='è·³è¿‡è¯„ä¼°é˜¶æ®µ')
    parser.add_argument('--skip-plots', action='store_true',
                       help='è·³è¿‡ç»˜å›¾')
    
    # å®éªŒå‚æ•°
    parser.add_argument('--max-papers', type=int,
                       help='æœ€å¤§ä¸‹è½½è®ºæ–‡æ•°')
    parser.add_argument('--max-samples', type=int,
                       help='æœ€å¤§è¯„ä¼°æ ·æœ¬æ•°')
    parser.add_argument('--attack-ratio', type=float,
                       help='æ”»å‡»æ ·æœ¬æ¯”ä¾‹')
    parser.add_argument('--advanced-attacks', action='store_true',
                       help='ä½¿ç”¨é«˜çº§æ”»å‡»ç”Ÿæˆå™¨')
    parser.add_argument('--ensemble-detector', action='store_true',
                       help='ä½¿ç”¨é›†æˆæ£€æµ‹å™¨')
    
    # è¾“å‡ºæ§åˆ¶
    parser.add_argument('--output-dir', type=str,
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--experiment-name', type=str,
                       help='å®éªŒåç§°')
    parser.add_argument('--save-all', action='store_true',
                       help='ä¿å­˜æ‰€æœ‰ä¸­é—´ç»“æœ')
    
    # æ—¥å¿—æ§åˆ¶
    parser.add_argument('--log-file', type=str,
                       help='æ—¥å¿—æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--verbose', '-v', action='store_true',
                       help='è¯¦ç»†è¾“å‡º')
    parser.add_argument('--quiet', '-q', action='store_true',
                       help='é™é»˜æ¨¡å¼')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    if args.quiet:
        log_level = "WARNING"
    elif args.verbose:
        log_level = "DEBUG"
    else:
        log_level = "INFO"
    
    logger = setup_logging(log_level, args.log_file)
    
    # å®éªŒå¼€å§‹
    start_time = time.time()
    experiment_name = args.experiment_name or f"experiment_{int(start_time)}"
    
    logger.info("=" * 80)
    logger.info(f"ğŸš€ å¼€å§‹å®éªŒ: {experiment_name}")
    logger.info("=" * 80)
    
    try:
        # åŠ è½½é…ç½®
        config = load_config(args.config)
        
        # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
        if args.max_papers:
            config['data_collection']['max_papers'] = args.max_papers
        
        if args.attack_ratio:
            config['attack_generation']['attack_ratio'] = args.attack_ratio
        
        if args.output_dir:
            config['experiment']['output_dir'] = args.output_dir
        
        # åˆ›å»ºå®éªŒç›®å½•
        output_dir = Path(config['experiment']['output_dir'])
        experiment_dir = output_dir / experiment_name
        experiment_dir.mkdir(parents=True, exist_ok=True)
        
        # æ›´æ–°é…ç½®ä¸­çš„è¾“å‡ºç›®å½•
        config['experiment']['output_dir'] = str(experiment_dir)
        config['attack_generation']['output_dir'] = str(experiment_dir / "attacks")
        
        logger.info(f"å®éªŒç›®å½•: {experiment_dir}")
        
        # ä¿å­˜å®éªŒé…ç½®
        config_file = experiment_dir / "experiment_config.json"
        save_results(config, str(config_file))
        
        # é˜¶æ®µ 1: æ•°æ®æ”¶é›†
        clean_files = run_data_collection(config, args, logger)
        
        if not clean_files:
            logger.error("æ•°æ®æ”¶é›†å¤±è´¥ï¼Œé€€å‡ºå®éªŒ")
            return 1
        
        # é˜¶æ®µ 2: æ”»å‡»ç”Ÿæˆ
        attack_files, attack_info = run_attack_generation(config, clean_files, args, logger)
        
        if not attack_files:
            logger.error("æ”»å‡»ç”Ÿæˆå¤±è´¥ï¼Œé€€å‡ºå®éªŒ")
            return 1
        
        # é˜¶æ®µ 3: æ£€æµ‹å’Œè¯„ä¼°
        if not args.skip_evaluation:
            evaluator, df_results, metrics = run_detection_evaluation(
                config, clean_files, attack_files, attack_info, args, logger
            )
            
            # ç”ŸæˆæŠ¥å‘Š
            logger.info("\nğŸ”„ é˜¶æ®µ 4: ç»“æœåˆ†æå’ŒæŠ¥å‘Š")
            logger.info("-" * 40)
            
            # ç»˜åˆ¶å›¾è¡¨
            if not args.skip_plots:
                try:
                    evaluator.plot_performance_analysis(df_results, metrics, save_plots=True)
                    logger.info("æ€§èƒ½åˆ†æå›¾è¡¨å·²ç”Ÿæˆ")
                except Exception as e:
                    logger.error(f"ç»˜å›¾å¤±è´¥: {e}")
            
            # ç”ŸæˆæŠ¥å‘Š
            report = evaluator.generate_report(df_results, metrics)
            logger.info("å®éªŒæŠ¥å‘Šå·²ç”Ÿæˆ")
            
            # ä¿å­˜å®éªŒæ€»ç»“
            experiment_summary = {
                'experiment_name': experiment_name,
                'start_time': start_time,
                'end_time': time.time(),
                'duration_seconds': time.time() - start_time,
                'config': config,
                'data_stats': {
                    'clean_files': len(clean_files),
                    'attack_files': len(attack_files)
                },
                'performance_metrics': metrics,
                'args': vars(args)
            }
            
            summary_file = experiment_dir / "experiment_summary.json"
            save_results(experiment_summary, str(summary_file))
            
            # æ‰“å°æœ€ç»ˆç»“æœ
            logger.info("\n" + "=" * 80)
            logger.info("ğŸ‰ å®éªŒå®Œæˆ")
            logger.info("=" * 80)
            logger.info(f"å®éªŒåç§°: {experiment_name}")
            logger.info(f"æ€»ç”¨æ—¶: {time.time() - start_time:.1f} ç§’")
            logger.info(f"å®éªŒç›®å½•: {experiment_dir}")
            logger.info("")
            logger.info("ğŸ“Š ä¸»è¦ç»“æœ:")
            logger.info(f"  å‡†ç¡®ç‡: {metrics['accuracy']:.3f}")
            logger.info(f"  ç²¾ç¡®ç‡: {metrics['precision']:.3f}")
            logger.info(f"  å¬å›ç‡: {metrics['recall']:.3f}")
            logger.info(f"  F1åˆ†æ•°: {metrics['f1_score']:.3f}")
            logger.info(f"  ROC AUC: {metrics['roc_auc']:.3f}")
            
        else:
            logger.info("è·³è¿‡è¯„ä¼°é˜¶æ®µ")
        
        logger.info("\nâœ… å®éªŒæˆåŠŸå®Œæˆï¼")
        return 0
        
    except KeyboardInterrupt:
        logger.warning("ç”¨æˆ·ä¸­æ–­å®éªŒ")
        return 1
    except Exception as e:
        logger.error(f"å®éªŒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        return 1

if __name__ == "__main__":
    exit(main())
